@article{Ying2004,
abstract = {We present a new fast multipole method for particle simulations. The main feature of our algorithm is that it does not require the implementation of multipole expansions of the underlying kernel, and it is based only on kernel evaluations. Instead of using analytic expansions to represent the potential generated by sources inside a box of the hierarchical FMM tree, we use a continuous distribution of an equivalent density on a surface enclosing the box. To find this equivalent density, we match its potential to the potential of the original sources at a surface, in the far field, by solving local Dirichlet-type boundary value problems. The far-field evaluations are sparsified with singular value decomposition in 2D or fast Fourier transforms in 3D. We have tested the new method on the single and double layer operators for the Laplacian, the modified Laplacian, the Stokes, the modified Stokes, the Navier, and the modified Navier operators in two and three dimensions. Our numerical results indicate that our method compares very well with the best known implementations of the analytic FMM method for both the Laplacian and modified Laplacian kernels. Its advantage is the (relative) simplicity of the implementation and its immediate extension to more general kernels. {\textcopyright} 2003 Elsevier Inc. All rights reserved.},
author = {Ying, Lexing and Biros, George and Zorin, Denis},
doi = {10.1016/j.jcp.2003.11.021},
file = {:home/sri/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ying, Biros, Zorin - 2004 - A kernel-independent adaptive fast multipole algorithm in two and three dimensions.pdf:pdf},
issn = {00219991},
journal = {Journal of Computational Physics},
keywords = {Double-layer potential,Fast multipole methods,Fast solvers,Integral equations,N-body problems,Particle methods,Single-layer potential},
mendeley-groups = {Masters},
number = {2},
pages = {591--626},
title = {{A kernel-independent adaptive fast multipole algorithm in two and three dimensions}},
volume = {196},
year = {2004}
}

@article{Lam2015,
abstract = {Dynamic, interpreted languages, like Python, are attractive for domain-experts and scientists experimenting with new ideas. However, the performance of the interpreter is of-ten a barrier when scaling to larger data sets. This paper presents a just-in-time compiler for Python that focuses in scientific and array-oriented computing. Starting with the simple syntax of Python, Numba compiles a subset of the language into efficient machine code that is comparable in performance to a traditional compiled language. In addi-tion, we share our experience in building a JIT compiler using LLVM[1].},
author = {Lam, Siu Kwan and Pitrou, Antoine and Seibert, Stanley},
file = {:home/sri/Documents/Mendeley/numba.pdf:pdf},
isbn = {9781450340052},
journal = {Proceedings of the Second Workshop on the LLVM Compiler Infrastructure in HPC - LLVM '15},
keywords = {2,a jit for numeric,com-,compiler,jit,just-in-time,llvm,numba is a function-at-a-time,python},
pages = {1--6},
title = {{Numba: a LLVM-based Python JIT compiler}},
url = {http://dl.acm.org/citation.cfm?doid=2833157.2833162},
year = {2015}
}

@article{Lashuk2012,
abstract = {We describe a parallel fast multipole method (FMM) for highly nonuniform distributions of particles. We employ both distributed memory parallelism (via MPI) and shared memory parallelism (via OpenMP and GPU acceleration) to rapidly evaluate two-body nonoscillatory potentials in three dimensions on heterogeneous high performance computing architectures. We have performed scalability tests with up to 30 billion particles on 196,608 cores on the AMD/ CRAY-based Jaguar system at ORNL. On a GPU-enabled system (NSF's Keeneland at Georgia Tech/ORNL), we observed 30× speedup over a single core CPU and 7× speedup over a multicore CPU implementation. By combining GPUs with MPI, we achieve less than 10 ns/particle and six digits of accuracy for a run with 48 million nonuniformly distributed particles on 192 GPUs. {\textcopyright} 2012 ACM.},
author = {Lashuk, Ilya and Chandramowlishwaran, Aparna and Langston, Harper and Nguyen, Tuan-Anh and Sampath, Rahul and Shringarpure, Aashay and Vuduc, Richard and Ying, Lexing and Zorin, Denis and Biros, George},
doi = {10.1145/2160718.2160740},
file = {:home/sri/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lashuk et al. - 2012 - A massively parallel adaptive fast multipole method on heterogeneous architectures.pdf:pdf},
issn = {0001-0782},
journal = {Communications of the ACM},
mendeley-groups = {Doctorate/FMMs},
month = {may},
number = {5},
pages = {101--109},
title = {{A massively parallel adaptive fast multipole method on heterogeneous architectures}},
url = {https://dl.acm.org/doi/10.1145/2160718.2160740},
volume = {55},
year = {2012}
}

@article{Malhotra2015,
abstract = {We describe our implementation of a parallel fast multipole method for evaluating potentials for discrete and continuous source distributions. The first requires summation over the source points and the second requiring integration over a continuous source density. Both problems require O(N 2) complexity when computed directly ; however, can be accelerated to O(N) time using FMM. In our PVFMM software library, we use kernel independent FMM and this allows us to compute potentials for a wide range of elliptic kernels. Our method is high order, adaptive and scalable. In this paper, we discuss several algorithmic improvements and performance optimizations including cache locality, vectorization, shared memory parallelism and use of coprocessors. Our distributed memory implementation uses space-filling curve for partitioning data and a hypercube communication scheme. We present convergence results for Laplace, Stokes and Helmholtz (low wavenumber) kernels for both particle and volume FMM. We measure efficiency of our method in terms of CPU cycles per unknown for different accuracies and different kernels. We also demonstrate scala-bility of our implementation up to several thousand processor cores on the Stampede platform at the Texas Advanced Computing Center.},
author = {Malhotra, Dhairya and Biros, George and Malhotra, D and Biros, G},
doi = {10.4208/cicp.020215.150515sw},
file = {:home/sri/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Malhotra et al. - 2015 - PVFMM A Parallel Kernel Independent FMM for Particle and Volume Potentials.pdf:pdf},
journal = {Commun. Comput. Phys.},
keywords = {35J05,65Y05,65Y20 Key words: Fast multipole method,AMS subject classifications: 31-04,N-body problems,potential theory},
mendeley-groups = {Masters},
number = {3},
pages = {808--830},
title = {{PVFMM: A Parallel Kernel Independent FMM for Particle and Volume Potentials}},
url = {http://www.global-sci.com/808https://www.cambridge.org/core/terms.https://doi.org/10.4208/cicp.020215.150515swDownloadedfromhttps://www.cambridge.org/core.UniversityCollegeLondon},
volume = {18},
year = {2015}
}

@article{Halko2011,
  title={Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions},
  author={Halko, Nathan and Martinsson, Per-Gunnar and Tropp, Joel A},
  journal={SIAM review},
  volume={53},
  number={2},
  pages={217--288},
  year={2011},
  publisher={SIAM}
}