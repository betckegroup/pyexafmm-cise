%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created for Lorena Barba at 2023-03-12 17:07:37 -0400 


%% Saved with string encoding Unicode (UTF-8) 



@article{Dongarra2000,
	author = {Dongarra, Jack and Sullivan, Francis},
	date-added = {2023-03-12 16:59:23 -0400},
	date-modified = {2023-03-12 17:00:31 -0400},
	doi = {10.1109/MCISE.2000.814652},
	journal = {Computing in Science \& Engineering},
	note = {doi: \href{https://doi.org/10.1109/MCISE.2000.814652}{10.1109/MCISE.2000.814652}},
	number = {01},
	pages = {22--23},
	publisher = {IEEE Computer Society},
	title = {Guest Editors Introduction to the top 10 algorithms},
	volume = {2},
	year = {2000}}

@article{Ying2004,
	abstract = {We present a new fast multipole method for particle simulations. The main feature of our algorithm is that it does not require the implementation of multipole expansions of the underlying kernel, and it is based only on kernel evaluations. Instead of using analytic expansions to represent the potential generated by sources inside a box of the hierarchical FMM tree, we use a continuous distribution of an equivalent density on a surface enclosing the box. To find this equivalent density, we match its potential to the potential of the original sources at a surface, in the far field, by solving local Dirichlet-type boundary value problems. The far-field evaluations are sparsified with singular value decomposition in 2D or fast Fourier transforms in 3D. We have tested the new method on the single and double layer operators for the Laplacian, the modified Laplacian, the Stokes, the modified Stokes, the Navier, and the modified Navier operators in two and three dimensions. Our numerical results indicate that our method compares very well with the best known implementations of the analytic FMM method for both the Laplacian and modified Laplacian kernels. Its advantage is the (relative) simplicity of the implementation and its immediate extension to more general kernels. {\textcopyright} 2003 Elsevier Inc. All rights reserved.},
	author = {Ying, Lexing and Biros, George and Zorin, Denis},
	date-modified = {2023-03-12 16:55:53 -0400},
	doi = {10.1016/j.jcp.2003.11.021},
	file = {:home/sri/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ying, Biros, Zorin - 2004 - A kernel-independent adaptive fast multipole algorithm in two and three dimensions.pdf:pdf},
	issn = {00219991},
	journal = {Journal of Computational Physics},
	keywords = {Double-layer potential,Fast multipole methods,Fast solvers,Integral equations,N-body problems,Particle methods,Single-layer potential},
	mendeley-groups = {Masters},
	note = {doi: \href{https://doi.org/10.1016/j.jcp.2003.11.021}{10.1016/j.jcp.2003.11.021}},
	number = {2},
	pages = {591--626},
	title = {{A kernel-independent adaptive fast multipole algorithm in two and three dimensions}},
	volume = {196},
	year = {2004},
	bdsk-url-1 = {https://doi.org/10.1016/j.jcp.2003.11.021}}

@article{Lam2015,
	abstract = {Dynamic, interpreted languages, like Python, are attractive for domain-experts and scientists experimenting with new ideas. However, the performance of the interpreter is of-ten a barrier when scaling to larger data sets. This paper presents a just-in-time compiler for Python that focuses in scientific and array-oriented computing. Starting with the simple syntax of Python, Numba compiles a subset of the language into efficient machine code that is comparable in performance to a traditional compiled language. In addi-tion, we share our experience in building a JIT compiler using LLVM[1].},
	author = {Lam, Siu Kwan and Pitrou, Antoine and Seibert, Stanley},
	date-modified = {2023-03-12 16:52:46 -0400},
	doi = {10.1145/2833157.2833162},
	file = {:home/sri/Documents/Mendeley/numba.pdf:pdf},
	isbn = {9781450340052},
	journal = {Proceedings of the Second Workshop on the LLVM Compiler Infrastructure in HPC - LLVM '15},
	keywords = {2,a jit for numeric,com-,compiler,jit,just-in-time,llvm,numba is a function-at-a-time,python},
	note = {doi: \href{https://doi.org/10.1145/2833157.2833162}{10.1145/2833157.2833162}},
	pages = {1--6},
	title = {{Numba: a LLVM-based Python JIT compiler}},
	url = {http://dl.acm.org/citation.cfm?doid=2833157.2833162},
	year = {2015},
	bdsk-url-1 = {http://dl.acm.org/citation.cfm?doid=2833157.2833162}}

@article{Lashuk2012,
	abstract = {We describe a parallel fast multipole method (FMM) for highly nonuniform distributions of particles. We employ both distributed memory parallelism (via MPI) and shared memory parallelism (via OpenMP and GPU acceleration) to rapidly evaluate two-body nonoscillatory potentials in three dimensions on heterogeneous high performance computing architectures. We have performed scalability tests with up to 30 billion particles on 196,608 cores on the AMD/ CRAY-based Jaguar system at ORNL. On a GPU-enabled system (NSF's Keeneland at Georgia Tech/ORNL), we observed 30× speedup over a single core CPU and 7× speedup over a multicore CPU implementation. By combining GPUs with MPI, we achieve less than 10 ns/particle and six digits of accuracy for a run with 48 million nonuniformly distributed particles on 192 GPUs. {\textcopyright} 2012 ACM.},
	author = {Lashuk, Ilya and Chandramowlishwaran, Aparna and Langston, Harper and Nguyen, Tuan-Anh and Sampath, Rahul and Shringarpure, Aashay and Vuduc, Richard and Ying, Lexing and Zorin, Denis and Biros, George},
	doi = {10.1145/2160718.2160740},
	file = {:home/sri/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lashuk et al. - 2012 - A massively parallel adaptive fast multipole method on heterogeneous architectures.pdf:pdf},
	issn = {0001-0782},
	journal = {Communications of the ACM},
	mendeley-groups = {Doctorate/FMMs},
	month = {may},
	number = {5},
	pages = {101--109},
	title = {{A massively parallel adaptive fast multipole method on heterogeneous architectures}},
	url = {https://dl.acm.org/doi/10.1145/2160718.2160740},
	volume = {55},
	year = {2012},
	bdsk-url-1 = {https://dl.acm.org/doi/10.1145/2160718.2160740},
	bdsk-url-2 = {https://doi.org/10.1145/2160718.2160740}}

@article{Malhotra2015,
	abstract = {We describe our implementation of a parallel fast multipole method for evaluating potentials for discrete and continuous source distributions. The first requires summation over the source points and the second requiring integration over a continuous source density. Both problems require O(N 2) complexity when computed directly ; however, can be accelerated to O(N) time using FMM. In our PVFMM software library, we use kernel independent FMM and this allows us to compute potentials for a wide range of elliptic kernels. Our method is high order, adaptive and scalable. In this paper, we discuss several algorithmic improvements and performance optimizations including cache locality, vectorization, shared memory parallelism and use of coprocessors. Our distributed memory implementation uses space-filling curve for partitioning data and a hypercube communication scheme. We present convergence results for Laplace, Stokes and Helmholtz (low wavenumber) kernels for both particle and volume FMM. We measure efficiency of our method in terms of CPU cycles per unknown for different accuracies and different kernels. We also demonstrate scala-bility of our implementation up to several thousand processor cores on the Stampede platform at the Texas Advanced Computing Center.},
	author = {Malhotra, Dhairya and Biros, George and Malhotra, D and Biros, G},
	doi = {10.4208/cicp.020215.150515sw},
	file = {:home/sri/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Malhotra et al. - 2015 - PVFMM A Parallel Kernel Independent FMM for Particle and Volume Potentials.pdf:pdf},
	journal = {Commun. Comput. Phys.},
	keywords = {35J05,65Y05,65Y20 Key words: Fast multipole method,AMS subject classifications: 31-04,N-body problems,potential theory},
	mendeley-groups = {Masters},
	number = {3},
	pages = {808--830},
	title = {{PVFMM: A Parallel Kernel Independent FMM for Particle and Volume Potentials}},
	url = {http://www.global-sci.com/808https://www.cambridge.org/core/terms.https://doi.org/10.4208/cicp.020215.150515swDownloadedfromhttps://www.cambridge.org/core.UniversityCollegeLondon},
	volume = {18},
	year = {2015},
	bdsk-url-1 = {http://www.global-sci.com/808https://www.cambridge.org/core/terms.https://doi.org/10.4208/cicp.020215.150515swDownloadedfromhttps://www.cambridge.org/core.UniversityCollegeLondon},
	bdsk-url-2 = {https://doi.org/10.4208/cicp.020215.150515sw}}

@article{Halko2011,
	author = {Halko, Nathan and Martinsson, Per-Gunnar and Tropp, Joel A},
	journal = {SIAM review},
	number = {2},
	pages = {217--288},
	publisher = {SIAM},
	title = {Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions},
	volume = {53},
	year = {2011}}

@article{Greengard1987,
	abstract = {An algorithm is presented for the rapid evaluation of the potential and force fields in systems involving large numbers of particles whose interactions are Coulombic or gravitational in nature. For a system of N particles, an amount of work of the order O(N2) has traditionally been required to evaluate all pairwise interactions, unless some approximation or truncation method is used. The algorithm of the present paper requires an amount of work proportional to N to evaluate all interactions to within roundoff error, making it considerably more practical for large-scale problems encountered in plasma physics, fluid dynamics, molecular dynamics, and celestial mechanics. {\textcopyright} 1987.},
	author = {Greengard, L. and Rokhlin, V.},
	date-modified = {2023-03-12 16:56:54 -0400},
	doi = {10.1016/0021-9991(87)90140-9},
	file = {:home/sri/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Greengard, Rokhlin - 1987 - A fast algorithm for particle simulations.pdf:pdf},
	issn = {10902716},
	journal = {Journal of Computational Physics},
	mendeley-groups = {Masters},
	note = {doi: \href{https://doi.org/10.1016/0021-9991(87)90140-9}{10.1016/0021-9991(87)90140-9}},
	number = {2},
	pages = {325--348},
	title = {{A fast algorithm for particle simulations}},
	volume = {73},
	year = {1987},
	bdsk-url-1 = {https://doi.org/10.1016/0021-9991(87)90140-9}}

@article{Engquist2007,
	abstract = {This paper introduces a new directional multilevel algorithm for solving N-body or AT-point problems with highly oscillatory kernels. These systems often result from the boundary integral formulations of scattering problems and are difficult due to the oscillatory nature of the kernel and the non-uniformity of the particle distribution. We address the problem by first proving that the interaction between a ball of radius r and a well-separated region has an approximate low rank representation, as long as the well-separated region belongs to a cone with a spanning angle of O(1/r) and is at a distance which is at least O(r2) away from from the ball. We then propose an efficient and accurate procedure which utilizes random sampling to generate such a separated, low rank representation. Based on the resulting representations, our new algorithm organizes the high frequency far field computation by a multidirectional and multiscale strategy to achieve maximum efficiency. The algorithm performs well on a large group of highly oscillatory kernels. Our algorithm is proved to have O(N log N) computational complexity for any given accuracy when the points are sampled from a two dimensional surface. We also provide numerical results to demonstrate these properties. {\textcopyright} 2007 Society for Industrial and Applied Mathematics.},
	author = {Engquist, Bj{\"{o}}rn and Ying, Lexing},
	doi = {10.1137/07068583X},
	file = {:home/sri/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Engquist, Ying - 2007 - Fast directional multilevel algorithms for oscillatory kernels(2).pdf:pdf},
	issn = {10648275},
	journal = {SIAM Journal on Scientific Computing},
	keywords = {Fast multipole methods,Helmholtz equation,Multidirectional computation,Multiscale methods,N-body problems,Operator compression,Oscillatory kernels,Random sampling,Scattering problems,Separated representations},
	number = {4},
	pages = {1710--1737},
	title = {{Fast directional multilevel algorithms for oscillatory kernels}},
	volume = {29},
	year = {2007},
	bdsk-url-1 = {https://doi.org/10.1137/07068583X}}

@article{Wang2021,
	author = {Wang, Tingyu and Yokota, Rio and Barba, Lorena A},
	date-modified = {2023-03-12 17:07:34 -0400},
	journal = {Journal of Open Source Software},
	note = {doi: \href{http://doi.org/10.21105/joss.03145}{10.21105/joss.03145}},
	number = {61},
	pages = {3145},
	title = {{ExaFMM}: a high-performance fast multipole method library with C++ and Python interfaces},
	volume = {6},
	year = {2021}}

@article{Fong2009,
	abstract = {A new O (N) fast multipole formulation is proposed for non-oscillatory kernels. This algorithm is applicable to kernels K (x, y) which are only known numerically, that is their numerical value can be obtained for any (x, y). This is quite different from many fast multipole methods which depend on analytical expansions of the far-field behavior of K, for | x - y | large. Other "black-box" or "kernel-independent" fast multipole methods have been devised. Our approach has the advantage of requiring a small pre-computation time even for very large systems, and uses the minimal number of coefficients to represent the far-field, for a given L2 tolerance error in the approximation. This technique can be very useful for problems where the kernel is known analytically but is quite complicated, or for kernels which are defined purely numerically. {\textcopyright} 2009 Elsevier Inc. All rights reserved.},
	author = {Fong, William and Darve, Eric},
	doi = {10.1016/j.jcp.2009.08.031},
	file = {:home/sri/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fong, Darve - 2009 - The black-box fast multipole method.pdf:pdf},
	issn = {10902716},
	journal = {Journal of Computational Physics},
	keywords = {Chebyshev polynomials,Fast multipole method,Interpolation,Singular value decomposition},
	month = {dec},
	number = {23},
	pages = {8712--8725},
	publisher = {Academic Press Inc.},
	title = {{The black-box fast multipole method}},
	volume = {228},
	year = {2009},
	bdsk-url-1 = {https://doi.org/10.1016/j.jcp.2009.08.031}}

@article{Martinsson2007,
	abstract = {A version of the fast multipole method (FMM) is described for charge distributions on the line. Previously published schemes of this type relied either on analytical representations of the potentials to be evaluated (multipoles, Legendre expansions, Taylor series, etc.) or on tailored representations that were constructed numerically (using, e.g., the singular value decomposition (SVD), artificial charges, etc.). The algorithm of this paper belongs to the second category, utilizing the matrix compression scheme described in [H. Cheng, Z. Gimbutas, P. G. Martinsson, and V. Rokhlin, SIAM J. Sci. Comput. 26 (2005), pp. 1389-1404]. The resulting scheme exhibits substantial improvements in the CPU time requirements. Furthermore, the scheme is applicable to a wide variety of potentials; in this respect, it is similar to the SVD-based FMMs. The performance of the method is illustrated with several numerical examples. {\textcopyright} 2007 Society for Industrial and Applied Mathematics.},
	author = {Martinsson, P G and Rokhlin, V},
	doi = {10.1137/060662253},
	file = {:home/sri/Documents/Mendeley/An_Accelerated_Kernel-Independ.pdf:pdf},
	issn = {10648275},
	journal = {SIAM Journal on Scientific Computing},
	keywords = {Fast multipole method,Fast summation,Matrix interpolation,Skeletonization},
	mendeley-groups = {Doctorate},
	number = {3},
	pages = {1160--1178},
	title = {{An accelerated kernel-independent fast multipole method in one dimension}},
	url = {http://www.siam.org/journals/sisc/29-3/66225.html},
	volume = {29},
	year = {2007},
	bdsk-url-1 = {http://www.siam.org/journals/sisc/29-3/66225.html},
	bdsk-url-2 = {https://doi.org/10.1137/060662253}}

@article{Gimbutas2003,
	abstract = {We present a modification of the fast multipole method (FMM) in two dimensions. While previous implementations of the FMM have been designed for harmonic kernels, our algorithm works for a large class of kernels that satisfy fairly general conditions, amounting to the kernel being sufficiently smooth away from the diagonal. Our algorithm approximates appropriately chosen parts of the kernel with "tensor products" of Legendre expansions and uses the singular value decomposition (SVD) to compress the resulting representations. The obtained singular function expansions replace the Taylor and Laurent expansions used in the original FMM. The algorithm requires O(N) operations and is stable and robust. The performance of the algorithm is illustrated with numerical examples.},
	author = {Gimbutas, Zyndrunas and Rokhlin, Vladimir},
	doi = {10.1137/S1064827500381148},
	file = {:home/sri/Documents/Mendeley/A_Generalized_Fast_Multipole_M.pdf:pdf},
	isbn = {1064827500},
	issn = {10648275},
	journal = {SIAM Journal on Scientific Computing},
	keywords = {Arbitrary kernels,Fast multipole method,Potential theory},
	number = {3},
	pages = {796--817},
	title = {{A generalized fast multipole method for nonoscillatory kernels}},
	volume = {24},
	year = {2003},
	bdsk-url-1 = {https://doi.org/10.1137/S1064827500381148}}

@article{Bramas2020,
	abstract = {TBFMM, for task-based FMM, is a high-performance package that implements the parallel fast multipole method (FMM) in modern C++17. It implements parallel strategies for multicore architectures, i.e. to run on a single computing node. TBFMM was designed to be easily cus-tomized thanks to C++ templates and fine control of the C++ classes' inter-dependencies. Users can implement new FMM kernels, new types of interacting elements or even new par-allelization strategies. As such, it can be used as a simulation toolbox for scientists in physics or applied mathematics. It enables users to perform simulations while delegating the data structure, the algorithm and the parallelization to the library. Besides, TBFMM can also provide an interesting use case for the HPC research community regarding parallelization, optimization and scheduling of applications handling irregular data structures.},
	author = {Bramas, Berenger},
	doi = {10.21105/joss.02444},
	file = {:home/sri/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bramas - Unknown - TBFMM A C generic and parallel fast multipole method library(3).pdf:pdf},
	issn = {2475-9066},
	journal = {Journal of Open Source Software},
	mendeley-groups = {Doctorate},
	number = {56},
	pages = {2444},
	title = {{TBFMM: A C++ generic and parallel fast multipole method library}},
	url = {https://doi.org/10.21105/joss.02444},
	volume = {5},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.21105/joss.02444}}

@article{Agullo2014,
	abstract = {Fast multipole methods (FMM) are a fundamental operation for the simulation of many physical problems. The high-performance design of such methods usually requires to carefully tune the algorithm for both the targeted physics and the hardware. In this paper, we propose a new approach that achieves high performance across architectures. Our method consists of expressing the FMM algorithm as a task flow and employing a state-of-the-art runtime system, StarPU, to process the tasks on the different computing units. We carefully design the task flow, the mathematical operators, their implementations, and scheduling schemes. Potentials and forces on 200 million particles are computed in 42.3 seconds on a homogeneous 160-core SGI Altix UV 100 and good scalability is shown. {\textcopyright} 2014 Society for Industrial and Applied Mathematics.},
	author = {Agullo, Emmanuel and Bramas, B{\'{e}}renger and Coulaud, Olivier and Darve, Eric and Messner, Matthias and Takahashi, Toru},
	doi = {10.1137/130915662},
	file = {:home/sri/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Agullo et al. - Unknown - TASK-BASED FMM FOR MULTICORE ARCHITECTURES.pdf:pdf},
	issn = {10957200},
	journal = {SIAM Journal on Scientific Computing},
	keywords = {Fast multipole methods,Multicore architectures,Pipeline,Runtime system,Shared memory paradigm},
	mendeley-groups = {Doctorate},
	number = {1},
	pages = {66--93},
	title = {{Task-based FMM for multicore architectures}},
	url = {http://www.siam.org/journals/sisc/36-1/91566.html},
	volume = {36},
	year = {2014},
	bdsk-url-1 = {http://www.siam.org/journals/sisc/36-1/91566.html},
	bdsk-url-2 = {https://doi.org/10.1137/130915662}}

@article{Agullo2016,
	abstract = {High performance fast multipole method is crucial for the numerical simulation of many physical problems. In a previous study, we have shown that task-based fast multipole method provides the flexibility required to process a wide spectrum of particle distributions efficiently on multicore architectures. In this paper, we now show how such an approach can be extended to fully exploit heterogeneous platforms. For that, we design highly tuned graphics processing unit (GPU) versions of the two dominant operators P2P and M2L) as well as a scheduling strategy that dynamically decides which proportion of subsequent tasks is processed on regular CPU cores and on GPU accelerators. We assess our method with the StarPU runtime system for executing the resulting task flow on an Intel X5650 Nehalem multicore processor possibly enhanced with one, two, or three Nvidia Fermi M2070 or M2090 GPUS (Santa Clara, CA, USA). A detailed experimental study on two 30 million particle distributions (a cube and an ellipsoid) shows that the resulting software consistently achieves high performance across architectures.},
	author = {Agullo, Emmanuel and Bramas, Berenger and Coulaud, Olivier and Darve, Eric and Messner, Matthias and Takahashi, Toru},
	doi = {10.1002/cpe.3723},
	file = {:home/sri/Documents/Mendeley/cpe.3723.pdf:pdf},
	issn = {15320634},
	journal = {Concurrency Computation},
	keywords = {fast multipole methods,graphics processing unit,heterogeneous architectures,pipeline,runtime system,scheduling},
	mendeley-groups = {Doctorate},
	month = {jun},
	number = {9},
	pages = {2608--2629},
	publisher = {John Wiley and Sons Ltd},
	title = {{Task-based FMM for heterogeneous architectures}},
	volume = {28},
	year = {2016},
	bdsk-url-1 = {https://doi.org/10.1002/cpe.3723}}

@software{Gimbutas2010,
	author = {{Gimbutas, Z and Greengard, Leslie}},
	date = {2021-03-18},
	title = {FMMLIB3D},
	url = {https://github.com/zgimbutas/fmmlib3d},
	version = {1.2.3},
	bdsk-url-1 = {https://github.com/zgimbutas/fmmlib3d}}

@software{Yokota2017,
	author = {{Yokota, Rio and Barba, Lorena A.}},
	date = {2017-03-03},
	title = {ExaFMM},
	url = {https://github.com/exafmm/exafmm},
	version = {9a8aac},
	bdsk-url-1 = {https://github.com/exafmm/exafmm}}

@software{anaconda,
	author = {{Continuum Analytics}},
	title = {Anaconda Software Distribution.},
	url = {https://anaconda.com/},
	version = {2-2.4.0},
	year = {2016-11-01},
	bdsk-url-1 = {https://anaconda.com/}}

@article{Sundar2007,
	abstract = {In this article, we propose new parallel algorithms for the construction and 2:1 balance refinement of large linear octrees on distributed memory machines. Such octrees are used in many problems in computational science and engineering, e.g., object representation, image analysis, unstructured meshing, finite elements, adaptive mesh refinement, and N-body simulations. Fixed-size scalability and isogranular analysis of the algorithms using an MPI-based parallel implementation was performed on a variety of input data and demonstrated good scalability for different processor counts (1 to 1024 processors) on the Pittsburgh Supercomputing Center's TCS-1 AlphaServer. The results are consistent for different data distributions. Octrees with over a billion octants were constructed and balanced in less than a minute on 1024 processors. Like other existing algorithms for constructing and balancing octrees, our algorithms have O(N log N) work and O(N) storage complexity. Under reasonable assumptions on the distribution of octants and the work per octant, the parallel time complexity is O(N/nP log(N/nP) + n P]og nP), where N is the size of the final linear octree and nP is the number of processors. {\textcopyright} 2008 Society for Industrial and Applied Mathematics.},
	author = {Sundar, Hari and Sampath, Rahul S. and Biros, George},
	date-modified = {2023-03-12 17:01:36 -0400},
	doi = {10.1137/070681727},
	file = {:home/sri/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/SUNDAR, SAMPATH,, BIROS - 2008 - BOTTOM-UP CONSTRUCTION AND 21 BALANCE REFINEMENT OF LINEAR OCTREES IN PARALLEL.pdf:pdf},
	issn = {10648275},
	journal = {SIAM Journal on Scientific Computing},
	keywords = {Balance refinement,Large scale parallel computing,Linear octrees,Morton encoding,Space filling curves},
	mendeley-groups = {Doctorate},
	note = {doi: \href{https://doi.org/10.1137/070681727}{10.1137/070681727}},
	number = {5},
	pages = {2675--2708},
	title = {{Bottom-up construction and 2:1 balance refinement of linear octrees in parallel}},
	volume = {30},
	year = {2007},
	bdsk-url-1 = {https://doi.org/10.1137/070681727}}

@techreport{Erichson,
	abstract = {Matrix decompositions are fundamental tools in the area of applied mathematics, statistical computing, and machine learning. In particular, low-rank matrix decompo-sitions are vital, and widely used for data analysis, dimensionality reduction, and data compression. Massive datasets, however, pose a computational challenge for traditional algorithms, placing significant constraints on both memory and processing power. Recently , the powerful concept of randomness has been introduced as a strategy to ease the computational load. The essential idea of probabilistic algorithms is to employ some amount of randomness in order to derive a smaller matrix from a high-dimensional data matrix. The smaller matrix is then used to compute the desired low-rank approximation. Such algorithms are shown to be computationally efficient for approximating matrices with low-rank structure. We present the R package rsvd, and provide a tutorial introduction to randomized matrix decompositions. Specifically, randomized routines for the singular value decomposition, (robust) principal component analysis, interpolative decomposition, and CUR decomposition are discussed. Several examples demonstrate the routines, and show the computational advantage over other methods implemented in R.},
	archiveprefix = {arXiv},
	arxivid = {1608.02148v5},
	author = {Erichson, N Benjamin and Voronin, Sergey and Brunton, Steven L and Kutz, J Nathan},
	eprint = {1608.02148v5},
	file = {:home/sri/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Erichson et al. - Unknown - Randomized Matrix Decompositions Using R.pdf:pdf},
	keywords = {CUR decomposition,R,dimension reduction,low-rank approximations,principal component analysis,randomized algorithm,singular value decomposition},
	mendeley-groups = {Doctorate},
	title = {{Randomized Matrix Decompositions Using R}}}

@inproceedings{Lattner2004,
	author = {Lattner, C. and Adve, V.},
	booktitle = {International Symposium on Code Generation and Optimization, 2004. CGO 2004.},
	date-modified = {2023-03-12 16:58:05 -0400},
	doi = {10.1109/CGO.2004.1281665},
	note = {doi: \href{https://doi.org/10.1109/CGO.2004.1281665}{10.1109/CGO.2004.1281665}},
	pages = {75-86},
	title = {{LLVM}: a compilation framework for lifelong program analysis amp; transformation},
	year = {2004},
	bdsk-url-1 = {https://doi.org/10.1109/CGO.2004.1281665}}

@manual{supported_python_features,
	note = {"Supported Python Features in Numba" Available at \url{https://numba.pydata.org/numba-doc/dev/reference/pysupported.html#generators}}}

@article{Cipra2000,
	author = {Cipra, Barry A.},
	file = {:home/sri/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cipra - 2000 - The Best of the 20th Century Editors Name Top 10 Algorithms.pdf:pdf},
	journal = {SIAM News},
	keywords = {Cointegration analysis,Death rate forecasting,Error correct model.,Traffic accident},
	mendeley-groups = {Masters},
	number = {4},
	title = {{The Best of the 20th Century: Editors Name Top 10 Algorithms}},
	url = {https://archive.siam.org/pdf/news/637.pdf},
	volume = {33},
	year = {2000},
	bdsk-url-1 = {https://archive.siam.org/pdf/news/637.pdf}}

@article{Malakhov2016,
	abstract = {Python is popular among numeric communities that value it for easy to use number crunching modules like [NumPy], [SciPy], [Dask], [Numba], and many others. These modules often use multi-threading for efficient multi-core parallelism in order to utilize all the available CPU cores. Nevertheless, their threads can interfere with each other leading to overhead and inefficiency if used together in one application. The loss of performance can be prevented if all the multi-threaded parties are coordinated. This paper describes usage of Intel{\textregistered} Threading Building Blocks (Intel{\textregistered} TBB), an open-source cross-platform library for multi-core parallelism [TBB], as the composability layer for Python modules. It helps to unlock additional performance for numeric applications on multi-core systems.},
	author = {Malakhov, Anton},
	doi = {10.25080/majora-629e541a-002},
	file = {:home/sri/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Malakhov - 2016 - Composable Multi-Threading for Python Libraries.pdf:pdf},
	journal = {Proceedings of the 15th Python in Science Conference},
	keywords = {Dask,GIL,Index Terms-Multi-threading,Joblib,Multi-core,Nested Parallelism,NumPy,Numba,Over-subscription,Parallel Computations,Python,SciPy,TBB},
	pages = {15--19},
	title = {{Composable Multi-Threading for Python Libraries}},
	url = {https://youtu.be/kfQcWez2URE},
	year = {2016},
	bdsk-url-1 = {https://youtu.be/kfQcWez2URE},
	bdsk-url-2 = {https://doi.org/10.25080/majora-629e541a-002}}
