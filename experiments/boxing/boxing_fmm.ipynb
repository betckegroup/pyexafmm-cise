{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from numba import njit, jit, objmode\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from fmm import Fmm\n",
    "from fmm.backend.numba import *\n",
    "from fmm.kernel import *\n",
    "\n",
    "import adaptoctree.morton as morton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numba Threading Layer Configuration\n",
    "\n",
    "## (Intel CPUs Only) Sets lifetime of OpenMP threads to 0ms\n",
    "## As computation contains large serial (Python) components\n",
    "! export KMP_BLOCKTIME=0\n",
    "\n",
    "## Limit number of threads created by BLAS/LAPACK functions\n",
    "## Called by Numpy\n",
    "! export OMP_NUM_THREADS=1\n",
    "\n",
    "## Define 'places' at which threads are assigned\n",
    "! export OMP_PLACES=cores\n",
    "\n",
    "## Makes thread assignment go succesively through available\n",
    "## places. In our case, through each core.\n",
    "! export OMP_PROC_BIND=close\n",
    "\n",
    "## Select OpenMP as threading layer for Numba, the uniformity\n",
    "## of FMM operators makes it preferable to TBB\n",
    "! export NUMBA_THREADING_LAYER='omp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! fmm generate-test-data -c test_config\n",
    "# ! fmm compute-operators -c test_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Fmm('test_config', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P2M: 0.4108006954193115\n",
      "M2M: 0.022339344024658203\n",
      "L2L: 0.02729201316833496\n",
      "M2L: 13.505892515182495\n",
      "L2T: 0.38305163383483887\n",
      "M2T: 0.006087779998779297\n",
      "S2L: 0.3993546962738037\n",
      "P2P: 0.39414548873901367\n"
     ]
    }
   ],
   "source": [
    "e.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2T: 0.3764176368713379\n",
    "\n",
    "M2T: 0.0062100887298583984\n",
    "\n",
    "S2L: 0.40326786041259766\n",
    "\n",
    "P2P: 0.4828755855560303"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.031/1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_times = {}\n",
    "\n",
    "def jit_timer(f):\n",
    "    \"\"\"Measure cpu time, i.e. excluding boxing/unboxing time\"\"\"\n",
    "    jf = njit(f)\n",
    "    @njit\n",
    "    def wrapper(*args):\n",
    "        with objmode(start='float64'):\n",
    "            start = time.time()\n",
    "        g = jf(*args)\n",
    "        with objmode():\n",
    "            end = time.time()\n",
    "            run_time = end - start\n",
    "            if f.__name__ in cpu_times:\n",
    "                cpu_times[f.__name__] += [run_time]\n",
    "            else:\n",
    "                cpu_times[f.__name__] = [run_time]\n",
    "        return g\n",
    "    return wrapper\n",
    "\n",
    "def jit_timer_parallel(f):\n",
    "    \"\"\"Measure cpu time, i.e. excluding boxing/unboxing time\"\"\"\n",
    "    jf = njit(f, parallel=True)\n",
    "    @njit\n",
    "    def wrapper(*args):\n",
    "        with objmode(start='float64'):\n",
    "            start = time.time()\n",
    "        g = jf(*args)\n",
    "        with objmode():\n",
    "            end = time.time()\n",
    "            run_time = end - start\n",
    "            if f.__name__ in cpu_times:\n",
    "                cpu_times[f.__name__] += [run_time]\n",
    "            else:\n",
    "                cpu_times[f.__name__] = [run_time]\n",
    "        return g\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit_timer_parallel\n",
    "def m2m(\n",
    "        keys,\n",
    "        multipole_expansions,\n",
    "        m2m,\n",
    "        key_to_index,\n",
    "        nequivalent_points,\n",
    "    ):\n",
    "\n",
    "    nkeys = len(keys)\n",
    "    for i in numba.prange(nkeys):\n",
    "        child = keys[i]\n",
    "        parent = morton.find_parent(child)\n",
    "\n",
    "        # Compute operator index\n",
    "        operator_idx = child == morton.find_siblings(child)\n",
    "\n",
    "        # Get parent and child expansion indices\n",
    "        child_idx = key_to_index[child]\n",
    "        child_lidx = child_idx*nequivalent_points\n",
    "        child_ridx = child_lidx+nequivalent_points\n",
    "        child_equivalent_density = multipole_expansions[child_lidx:child_ridx]\n",
    "\n",
    "        parent_idx = key_to_index[parent]\n",
    "        parent_lidx = parent_idx*nequivalent_points\n",
    "        parent_ridx = parent_lidx+nequivalent_points\n",
    "        \n",
    "        # Add child contribution to parent multipole expansion\n",
    "        multipole_expansions[parent_lidx:parent_ridx] += m2m[operator_idx][0] @ child_equivalent_density\n",
    "#         m2m[operator_idx][0] @ child_equivalent_density\n",
    "\n",
    "@jit_timer_parallel\n",
    "def l2l(\n",
    "    keys,\n",
    "    local_expansions,\n",
    "    l2l,\n",
    "    key_to_index,\n",
    "    nequivalent_points\n",
    "):\n",
    "    nkeys = len(keys)\n",
    "    for i in numba.prange(nkeys):\n",
    "        child = keys[i]\n",
    "        parent = morton.find_parent(child)\n",
    "\n",
    "        # Compute operator index\n",
    "        operator_idx = child == morton.find_siblings(child)\n",
    "\n",
    "        parent_idx = key_to_index[parent]\n",
    "        parent_lidx = parent_idx*nequivalent_points\n",
    "        parent_ridx = parent_lidx+nequivalent_points\n",
    "        parent_equivalent_density = local_expansions[parent_lidx:parent_ridx]\n",
    "\n",
    "        # Compute expansion index\n",
    "        child_idx = key_to_index[child]\n",
    "        child_lidx = child_idx*nequivalent_points\n",
    "        child_ridx = child_lidx+nequivalent_points\n",
    "\n",
    "        # Compute contribution to local expansion of child from parent\n",
    "        local_expansions[child_lidx:child_ridx] += l2l[operator_idx][0] @ parent_equivalent_density\n",
    "#         l2l[operator_idx][0] @ parent_equivalent_density\n",
    "\n",
    "\n",
    "@jit_timer_parallel\n",
    "def m2l(\n",
    "        keys,\n",
    "        v_lists,\n",
    "        u,\n",
    "        s,\n",
    "        vt,\n",
    "        dc2e_inv_a,\n",
    "        dc2e_inv_b,\n",
    "        multipole_expansions,\n",
    "        local_expansions,\n",
    "        nequivalent_points,\n",
    "        key_to_index,\n",
    "        hash_to_index,\n",
    "        scale\n",
    "    ):\n",
    "    nkeys = len(keys)\n",
    "\n",
    "    for i in numba.prange(nkeys):\n",
    "        key = keys[i]\n",
    "\n",
    "        # Pick out the v list\n",
    "        v_list = v_lists[key_to_index[key]]\n",
    "\n",
    "        # Filter v list\n",
    "        v_list = v_list[v_list != -1]\n",
    "        v_list = v_list[v_list != 0]\n",
    "\n",
    "        \n",
    "        nv_list = len(v_list)\n",
    "\n",
    "        # Indices of local expansion\n",
    "        l_lidx = key_to_index[key]*nequivalent_points\n",
    "        l_ridx = l_lidx+nequivalent_points\n",
    "\n",
    "        for j in range(nv_list):\n",
    "\n",
    "            source = v_list[j]\n",
    "\n",
    "            # Locd correct components of compressed M2L matrix\n",
    "            transfer_vector = morton.find_transfer_vector(key, source)\n",
    "            v_idx = hash_to_index[transfer_vector]\n",
    "            v_lidx = v_idx*nequivalent_points\n",
    "            v_ridx = v_lidx+nequivalent_points\n",
    "            vt_sub = np.copy(vt[:, v_lidx:v_ridx])\n",
    "\n",
    "            # Indices of multipole expansion\n",
    "            m_lidx = key_to_index[source]*nequivalent_points\n",
    "            m_ridx = m_lidx+nequivalent_points\n",
    "\n",
    "            local_expansions[l_lidx:l_ridx] += scale*(\n",
    "                dc2e_inv_a @ (\n",
    "                    dc2e_inv_b @ (\n",
    "                        u @ (s @ (vt_sub @ multipole_expansions[m_lidx:m_ridx]))\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            \n",
    "\n",
    "# @numba.njit(cache=True, parallel=True)\n",
    "@jit_timer_parallel\n",
    "def prepare_p2m_data(\n",
    "        leaves,\n",
    "        nleaves,\n",
    "        sources,\n",
    "        source_densities,\n",
    "        source_index_pointer,\n",
    "        key_to_leaf_index,\n",
    "        x0,\n",
    "        r0,\n",
    "        alpha_outer,\n",
    "        check_surface,\n",
    "        ncheck_points,\n",
    "        p2p_function,\n",
    "        scale_function,\n",
    "        dtype,\n",
    "    ):\n",
    "    scales = np.zeros(shape=nleaves, dtype=dtype)\n",
    "    check_potentials = np.zeros(shape=(nleaves*ncheck_points), dtype=dtype)\n",
    "\n",
    "    for thread_idx in numba.prange(nleaves):\n",
    "\n",
    "        leaf = leaves[thread_idx]\n",
    "\n",
    "        # Lookup leaf sources, and leaf source densities\n",
    "        leaf_idx = key_to_leaf_index[leaf]\n",
    "        leaf_sources = sources[source_index_pointer[leaf_idx]:source_index_pointer[leaf_idx+1]]\n",
    "        leaf_source_densities = source_densities[source_index_pointer[leaf_idx]:source_index_pointer[leaf_idx+1]]\n",
    "\n",
    "        # Compute center of leaf box in cartesian coordinates\n",
    "        leaf_center = morton.find_physical_center_from_key(\n",
    "            key=leaf, x0=x0, r0=r0\n",
    "        )\n",
    "\n",
    "        leaf_level = morton.find_level(leaf)\n",
    "\n",
    "        upward_check_surface = surface.scale_surface(\n",
    "            surf=check_surface,\n",
    "            radius=r0,\n",
    "            level=leaf_level,\n",
    "            center=leaf_center,\n",
    "            alpha=alpha_outer,\n",
    "        )\n",
    "\n",
    "        check_potential = p2p_function(\n",
    "            targets=upward_check_surface,\n",
    "            sources=leaf_sources,\n",
    "            source_densities=leaf_source_densities,\n",
    "        )\n",
    "\n",
    "        lidx = thread_idx*ncheck_points\n",
    "        ridx = lidx+ncheck_points\n",
    "        check_potentials[lidx:ridx] += check_potential\n",
    "        scales[thread_idx] += scale_function(leaf_level)\n",
    "\n",
    "    return scales, check_potentials\n",
    "\n",
    "\n",
    "@jit_timer_parallel\n",
    "def p2m_core(\n",
    "        leaves,\n",
    "        nleaves,\n",
    "        key_to_index,\n",
    "        nequivalent_points,\n",
    "        ncheck_points,\n",
    "        uc2e_inv_a,\n",
    "        uc2e_inv_b,\n",
    "        scales,\n",
    "        multipole_expansions,\n",
    "        check_potentials\n",
    "    ):\n",
    "    for i in numba.prange(nleaves):\n",
    "\n",
    "        scale = scales[i]\n",
    "\n",
    "        check_lidx = i*ncheck_points\n",
    "        check_ridx = check_lidx+ncheck_points\n",
    "        check_potential = check_potentials[check_lidx:check_ridx]\n",
    "\n",
    "        leaf = leaves[i]\n",
    "        lidx = key_to_index[leaf]*nequivalent_points\n",
    "        ridx = lidx+nequivalent_points\n",
    "\n",
    "        multipole_expansions[lidx:ridx] += scale*(uc2e_inv_a @ (uc2e_inv_b @ check_potential))\n",
    "        \n",
    "\n",
    "@numba.njit(cache=True)\n",
    "def p2m(\n",
    "        leaves,\n",
    "        nleaves,\n",
    "        key_to_index,\n",
    "        key_to_leaf_index,\n",
    "        sources,\n",
    "        source_densities,\n",
    "        source_index_pointer,\n",
    "        multipole_expansions,\n",
    "        nequivalent_points,\n",
    "        x0,\n",
    "        r0,\n",
    "        alpha_outer,\n",
    "        check_surface,\n",
    "        ncheck_points,\n",
    "        uc2e_inv_a,\n",
    "        uc2e_inv_b,\n",
    "        p2p_function,\n",
    "        scale_function,\n",
    "        dtype\n",
    "    ):\n",
    "\n",
    "    scales, check_potentials = prepare_p2m_data(\n",
    "        leaves=leaves,\n",
    "        nleaves=nleaves,\n",
    "        sources=sources,\n",
    "        source_densities=source_densities,\n",
    "        source_index_pointer=source_index_pointer,\n",
    "        key_to_leaf_index=key_to_leaf_index,\n",
    "        x0=x0,\n",
    "        r0=r0,\n",
    "        alpha_outer=alpha_outer,\n",
    "        check_surface=check_surface,\n",
    "        ncheck_points=ncheck_points,\n",
    "        p2p_function=p2p_function,\n",
    "        scale_function=scale_function,\n",
    "        dtype=dtype\n",
    "    )\n",
    "\n",
    "    p2m_core(\n",
    "        leaves=leaves,\n",
    "        nleaves=nleaves,\n",
    "        key_to_index=key_to_index,\n",
    "        nequivalent_points=nequivalent_points,\n",
    "        ncheck_points=ncheck_points,\n",
    "        uc2e_inv_a=uc2e_inv_a,\n",
    "        uc2e_inv_b=uc2e_inv_b,\n",
    "        scales=scales,\n",
    "        multipole_expansions=multipole_expansions,\n",
    "        check_potentials=check_potentials\n",
    "    )\n",
    "    \n",
    "\n",
    "@jit_timer_parallel\n",
    "def s2l(\n",
    "        leaves,\n",
    "        nleaves,\n",
    "        sources,\n",
    "        source_densities,\n",
    "        source_index_pointer,\n",
    "        key_to_index,\n",
    "        key_to_leaf_index,\n",
    "        x_lists,\n",
    "        local_expansions,\n",
    "        x0,\n",
    "        r0,\n",
    "        alpha_inner,\n",
    "        check_surface,\n",
    "        nequivalent_points,\n",
    "        dc2e_inv_a,\n",
    "        dc2e_inv_b,\n",
    "        scale_function,\n",
    "        p2p_function,\n",
    "        dtype\n",
    "    ):\n",
    "\n",
    "    nleaves = len(leaves)\n",
    "\n",
    "    for i in numba.prange(nleaves):\n",
    "\n",
    "        # Pick out leaf\n",
    "        leaf = leaves[i]\n",
    "\n",
    "        # Calculate downward check surface\n",
    "        level = morton.find_level(leaf)\n",
    "        scale = dtype(scale_function(level))\n",
    "        center = morton.find_physical_center_from_key(leaf, x0, r0)\n",
    "\n",
    "        downward_check_surface = surface.scale_surface(\n",
    "            surf=check_surface,\n",
    "            radius=r0,\n",
    "            level=level,\n",
    "            center=center,\n",
    "            alpha=alpha_inner\n",
    "        )\n",
    "\n",
    "        # Pick out X list\n",
    "        key_idx = key_to_index[leaf]\n",
    "        key_lidx = key_idx*nequivalent_points\n",
    "        key_ridx = key_lidx+nequivalent_points\n",
    "\n",
    "        x_list = x_lists[key_idx]\n",
    "        x_list = x_list[x_list != -1]\n",
    "\n",
    "        # Apply S2L operator over X list\n",
    "        for source in x_list:\n",
    "\n",
    "            source_index = key_to_leaf_index[source]\n",
    "            coordinates = sources[source_index_pointer[source_index]:source_index_pointer[source_index+1]]\n",
    "            densities = source_densities[source_index_pointer[source_index]:source_index_pointer[source_index+1]]\n",
    "\n",
    "            downward_check_potential = p2p_function(\n",
    "                sources=coordinates,\n",
    "                targets=downward_check_surface,\n",
    "                source_densities=densities\n",
    "            )\n",
    "\n",
    "            local_expansions[key_lidx:key_ridx] += scale*(dc2e_inv_a @ (dc2e_inv_b @ downward_check_potential))\n",
    "\n",
    "\n",
    "@jit_timer_parallel\n",
    "def m2t(\n",
    "        leaves,\n",
    "        nleaves,\n",
    "        w_lists,\n",
    "        targets,\n",
    "        target_index_pointer,\n",
    "        key_to_index,\n",
    "        key_to_leaf_index,\n",
    "        target_potentials,\n",
    "        multipole_expansions,\n",
    "        x0,\n",
    "        r0,\n",
    "        alpha_inner,\n",
    "        equivalent_surface,\n",
    "        nequivalent_points,\n",
    "        p2p_function,\n",
    "        gradient_function\n",
    "    ):\n",
    "    for i in numba.prange(nleaves):\n",
    "        target_key = leaves[i]\n",
    "        global_idx = key_to_index[target_key]\n",
    "        leaf_idx = key_to_leaf_index[target_key]\n",
    "        w_list = w_lists[global_idx]\n",
    "        w_list = w_list[w_list != -1]\n",
    "\n",
    "        # Coordinates of targets within leaf node\n",
    "        target_coordinates = targets[\n",
    "            target_index_pointer[leaf_idx]:target_index_pointer[leaf_idx+1]\n",
    "        ]\n",
    "\n",
    "        for source in w_list:\n",
    "            source_idx = key_to_index[source]\n",
    "            source_lidx = source_idx*nequivalent_points\n",
    "            source_ridx = source_lidx+nequivalent_points\n",
    "\n",
    "            source_level = morton.find_level(source)\n",
    "            source_center = morton.find_physical_center_from_key(source, x0, r0)\n",
    "\n",
    "            upward_equivalent_surface = surface.scale_surface(\n",
    "                surf=equivalent_surface,\n",
    "                radius=r0,\n",
    "                level=source_level,\n",
    "                center=source_center,\n",
    "                alpha=alpha_inner\n",
    "            )\n",
    "\n",
    "            target_idx = key_to_leaf_index[target_key]\n",
    "\n",
    "            target_potentials[target_index_pointer[target_idx]:target_index_pointer[target_idx+1], 0] += p2p_function(\n",
    "                sources=upward_equivalent_surface,\n",
    "                targets=target_coordinates,\n",
    "                source_densities=multipole_expansions[source_lidx:source_ridx]\n",
    "            )\n",
    "\n",
    "            target_potentials[target_index_pointer[target_idx]:target_index_pointer[target_idx+1], 1:] += gradient_function(\n",
    "                sources=upward_equivalent_surface,\n",
    "                targets=target_coordinates,\n",
    "                source_densities=multipole_expansions[source_lidx:source_ridx]\n",
    "            )\n",
    "\n",
    "\n",
    "@jit_timer\n",
    "def prepare_l2t_data(\n",
    "        leaves,\n",
    "        nleaves,\n",
    "        targets,\n",
    "        target_index_pointer,\n",
    "        equivalent_surface,\n",
    "        nequivalent_points,\n",
    "        x0,\n",
    "        r0,\n",
    "        alpha_outer,\n",
    "        key_to_index,\n",
    "        key_to_leaf_index,\n",
    "        local_expansions,\n",
    "        dtype,\n",
    "    ):\n",
    "\n",
    "    local_sources = np.zeros((nequivalent_points*nleaves, 3), dtype=dtype)\n",
    "    local_source_densities = np.zeros((nequivalent_points*nleaves), dtype=dtype)\n",
    "    local_targets = np.zeros((nequivalent_points*nleaves, 3), dtype=dtype)\n",
    "    local_source_index_pointer = np.zeros(nleaves+1, np.int64)\n",
    "    local_target_index_pointer = np.zeros(nleaves+1, np.int64)\n",
    "\n",
    "    source_ptr = 0\n",
    "    target_ptr = 0\n",
    "    local_source_index_pointer[0] = source_ptr\n",
    "    local_target_index_pointer[0] = target_ptr\n",
    "\n",
    "    for i in range(nleaves):\n",
    "        target = leaves[i]\n",
    "        level = morton.find_level(target)\n",
    "        center = morton.find_physical_center_from_key(target, x0, r0)\n",
    "        target_leaf_index = key_to_leaf_index[target]\n",
    "\n",
    "        targets_at_node = targets[\n",
    "            target_index_pointer[target_leaf_index]:target_index_pointer[target_leaf_index+1]\n",
    "        ]\n",
    "\n",
    "        sources_at_node = surface.scale_surface(\n",
    "            equivalent_surface,\n",
    "            r0,\n",
    "            level,\n",
    "            center,\n",
    "            alpha_outer\n",
    "        )\n",
    "\n",
    "        source_idx = key_to_index[target]\n",
    "        source_lidx = source_idx*nequivalent_points\n",
    "        source_ridx = source_lidx+nequivalent_points\n",
    "\n",
    "        source_densities_at_node = local_expansions[source_lidx:source_ridx]\n",
    "\n",
    "        ntargets_at_node = len(targets_at_node)\n",
    "        new_target_ptr = target_ptr+ntargets_at_node\n",
    "\n",
    "        local_targets[target_ptr:new_target_ptr] = targets_at_node\n",
    "        target_ptr = new_target_ptr\n",
    "\n",
    "        local_target_index_pointer[i+1] = target_ptr\n",
    "\n",
    "        nsources_at_node = len(sources_at_node)\n",
    "        new_source_ptr = source_ptr+nsources_at_node\n",
    "\n",
    "        local_sources[source_ptr:new_source_ptr] = sources_at_node\n",
    "        local_source_densities[source_ptr:new_source_ptr] = source_densities_at_node\n",
    "        source_ptr = new_source_ptr\n",
    "\n",
    "        local_source_index_pointer[i+1] = source_ptr\n",
    "\n",
    "    return local_sources, local_targets, local_source_densities, local_source_index_pointer, local_target_index_pointer\n",
    "\n",
    "\n",
    "@jit_timer\n",
    "def l2t(\n",
    "        leaves,\n",
    "        nleaves,\n",
    "        key_to_index,\n",
    "        key_to_leaf_index,\n",
    "        targets,\n",
    "        target_potentials,\n",
    "        target_index_pointer,\n",
    "        local_expansions,\n",
    "        x0,\n",
    "        r0,\n",
    "        alpha_outer,\n",
    "        equivalent_surface,\n",
    "        nequivalent_points,\n",
    "        p2p_parallel_function,\n",
    "        dtype\n",
    "    ):\n",
    "\n",
    "    local_sources, local_targets, local_source_densities, local_source_index_pointer, local_target_index_pointer = prepare_l2t_data(\n",
    "        leaves,\n",
    "        nleaves,\n",
    "        targets,\n",
    "        target_index_pointer,\n",
    "        equivalent_surface,\n",
    "        nequivalent_points,\n",
    "        x0,\n",
    "        r0,\n",
    "        alpha_outer,\n",
    "        key_to_index,\n",
    "        key_to_leaf_index,\n",
    "        local_expansions,\n",
    "        dtype\n",
    "    )\n",
    "\n",
    "    target_potentials_vec = p2p_parallel_function(\n",
    "        sources=local_sources,\n",
    "        targets=local_targets,\n",
    "        source_densities=local_source_densities,\n",
    "        source_index_pointer=local_source_index_pointer,\n",
    "        target_index_pointer=local_target_index_pointer\n",
    "    )\n",
    "\n",
    "    for i in range(nleaves):\n",
    "        res = target_potentials_vec[local_target_index_pointer[i]:local_target_index_pointer[i+1]]\n",
    "        leaf = leaves[i]\n",
    "        leaf_idx = key_to_leaf_index[leaf]\n",
    "        target_potentials[target_index_pointer[leaf_idx]:target_index_pointer[leaf_idx+1], :] += res\n",
    "\n",
    "\n",
    "@jit_timer_parallel\n",
    "def near_field(\n",
    "    leaves,\n",
    "    nleaves,\n",
    "    key_to_leaf_index,\n",
    "    key_to_index,\n",
    "    targets,\n",
    "    u_lists,\n",
    "    target_index_pointer,\n",
    "    sources,\n",
    "    source_densities,\n",
    "    source_index_pointer,\n",
    "    target_potentials,\n",
    "    p2p_function,\n",
    "    p2p_gradient_function\n",
    "):\n",
    "\n",
    "    for i in numba.prange(nleaves):\n",
    "        target = leaves[i]\n",
    "        target_leaf_index = key_to_leaf_index[target]\n",
    "        target_index = key_to_index[target]\n",
    "        targets_at_node = targets[\n",
    "            target_index_pointer[target_leaf_index]:target_index_pointer[target_leaf_index+1]\n",
    "        ]\n",
    "\n",
    "        u_list = u_lists[target_index]\n",
    "        u_list = u_list[u_list != -1]\n",
    "\n",
    "        # single threaded over inner loop over u list!\n",
    "        for j in range(len(u_list)):\n",
    "            source = u_list[j]\n",
    "            source_leaf_index = key_to_leaf_index[source]\n",
    "\n",
    "            sources_at_node = sources[\n",
    "                source_index_pointer[source_leaf_index]:source_index_pointer[source_leaf_index+1]\n",
    "            ]\n",
    "\n",
    "            source_densities_at_node = source_densities[\n",
    "                source_index_pointer[source_leaf_index]:source_index_pointer[source_leaf_index+1]\n",
    "            ]\n",
    "\n",
    "            target_potentials[target_index_pointer[target_leaf_index]:target_index_pointer[target_leaf_index+1],1:] += \\\n",
    "                p2p_gradient_function(sources_at_node, targets_at_node, source_densities_at_node)\n",
    "            target_potentials[target_index_pointer[target_leaf_index]:target_index_pointer[target_leaf_index+1], 0] += \\\n",
    "               p2p_function(sources_at_node, targets_at_node, source_densities_at_node)\n",
    "\n",
    "\n",
    "        # Now compute contribution due to sources in the node itself\n",
    "        sources_at_node = sources[\n",
    "            source_index_pointer[target_leaf_index]:source_index_pointer[target_leaf_index+1]\n",
    "        ]\n",
    "\n",
    "        source_densities_at_node = source_densities[\n",
    "            source_index_pointer[target_leaf_index]:source_index_pointer[target_leaf_index+1]\n",
    "        ]\n",
    "\n",
    "        target_potentials[target_index_pointer[target_leaf_index]:target_index_pointer[target_leaf_index+1],1:] += \\\n",
    "            p2p_gradient_function(sources_at_node, targets_at_node, source_densities_at_node)\n",
    "        target_potentials[target_index_pointer[target_leaf_index]:target_index_pointer[target_leaf_index+1], 0] += \\\n",
    "           p2p_function(sources_at_node, targets_at_node, source_densities_at_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "operators = ['m2m', 'l2l', 'm2l', 'm2p', 'p2l', 'near_field', 'l2p', 'p2m']\n",
    "\n",
    "wall_times_mean = {}\n",
    "wall_times_std = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wall Times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Near Field Wall Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrials = 5\n",
    "near_fieldvec = []\n",
    "\n",
    "for n in range(ntrials):\n",
    "    \n",
    "    s = time.time()\n",
    "    \n",
    "    e.backend['near_field'](\n",
    "    e.leaves,\n",
    "    e.nleaves,\n",
    "    e.key_to_leaf_index,\n",
    "    e.key_to_index,\n",
    "    e.targets,\n",
    "    e.u_lists,\n",
    "    e.target_index_pointer,\n",
    "    e.sources,\n",
    "    e.source_densities,\n",
    "    e.source_index_pointer,\n",
    "    e.target_potentials,\n",
    "    e.p2p_function,\n",
    "    e.gradient_function,\n",
    "    )\n",
    "    near_fieldvec.append(time.time()-s)\n",
    "    \n",
    "near_fieldvec = np.array(near_fieldvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_times_mean['near_field'] = near_fieldvec.mean()*1e3\n",
    "wall_times_std['near_field'] = near_fieldvec.std()*1e3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) P2L Wall Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrials = 5\n",
    "\n",
    "p2l_vec = np.zeros(ntrials)\n",
    "\n",
    "for n in range(ntrials):\n",
    "    s = time.time()\n",
    "    e.backend['s2l'](\n",
    "        leaves=e.leaves,\n",
    "        nleaves=e.nleaves,\n",
    "        sources=e.sources,\n",
    "        source_densities=e.source_densities,\n",
    "        source_index_pointer=e.source_index_pointer,\n",
    "        key_to_index=e.key_to_index,\n",
    "        key_to_leaf_index=e.key_to_leaf_index,\n",
    "        x_lists=e.x_lists,\n",
    "        local_expansions=e.local_expansions,\n",
    "        x0=e.x0,\n",
    "        r0=e.r0,\n",
    "        alpha_inner=e.alpha_inner,\n",
    "        check_surface=e.check_surface,\n",
    "        nequivalent_points=e.nequivalent_points,\n",
    "        dc2e_inv_a=e.dc2e_inv_a,\n",
    "        dc2e_inv_b=e.dc2e_inv_b,\n",
    "        scale_function=e.scale_function,\n",
    "        p2p_function=e.p2p_function,  \n",
    "        dtype=e.numpy_dtype\n",
    "    )\n",
    "    p2l_vec[n] = time.time()-s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_times_mean['p2l'] = p2l_vec.mean()*1000\n",
    "wall_times_std['p2l'] = p2l_vec.std()*1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) M2P Wall Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrials = 5\n",
    "\n",
    "m2p_vec = np.zeros(ntrials)\n",
    "\n",
    "for n in range(ntrials):\n",
    "    s = time.time()\n",
    "    e.backend['m2t'](\n",
    "        leaves=e.leaves,\n",
    "        nleaves=e.nleaves,\n",
    "        w_lists=e.w_lists,\n",
    "        targets=e.targets,\n",
    "        target_index_pointer=e.target_index_pointer,\n",
    "        key_to_index=e.key_to_index,\n",
    "        key_to_leaf_index=e.key_to_leaf_index,\n",
    "        target_potentials=e.target_potentials,\n",
    "        multipole_expansions=e.multipole_expansions,\n",
    "        x0=e.x0,\n",
    "        r0=e.r0,\n",
    "        alpha_inner=e.alpha_inner,\n",
    "        equivalent_surface=e.equivalent_surface,\n",
    "        nequivalent_points=e.nequivalent_points,\n",
    "        p2p_function=e.p2p_function,\n",
    "        gradient_function=e.gradient_function\n",
    "    )\n",
    "    m2p_vec[n] = time.time()-s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_times_mean['m2p'] = m2p_vec.mean()*1000\n",
    "wall_times_std['m2p'] = m2p_vec.std()*1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a) L2P Wall Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrials = 5\n",
    "\n",
    "l2p_vec = np.zeros(ntrials)\n",
    "\n",
    "for n in range(ntrials):\n",
    "    e.backend['l2t'](\n",
    "        leaves=e.leaves,\n",
    "        nleaves=e.nleaves,\n",
    "        key_to_index=e.key_to_index,\n",
    "        key_to_leaf_index=e.key_to_leaf_index,\n",
    "        targets=e.targets,\n",
    "        target_potentials=e.target_potentials,\n",
    "        target_index_pointer=e.target_index_pointer,\n",
    "        local_expansions=e.local_expansions,\n",
    "        x0=e.x0,\n",
    "        r0=e.r0,\n",
    "        alpha_outer=e.alpha_outer,\n",
    "        equivalent_surface=e.equivalent_surface,\n",
    "        nequivalent_points=e.nequivalent_points,\n",
    "        p2p_parallel_function=e.p2p_parallel_function,\n",
    "        dtype=e.numpy_dtype\n",
    "    )\n",
    "    l2p_vec[n] = s-time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_times_mean['l2p'] = l2p_vec.mean()*1000\n",
    "wall_times_std['l2p'] = l2p_vec.std()*1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b) L2P Organization Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrials = 5\n",
    "\n",
    "l2p_vec = np.zeros(ntrials)\n",
    "\n",
    "for n in range(ntrials):\n",
    "    s = time.time()\n",
    "    prepare_l2t_data(\n",
    "            e.leaves,\n",
    "            e.nleaves,\n",
    "            e.targets,\n",
    "            e.target_index_pointer,\n",
    "            e.equivalent_surface,\n",
    "            e.nequivalent_points,\n",
    "            e.x0,\n",
    "            e.r0,\n",
    "            e.alpha_outer,\n",
    "            e.key_to_index,\n",
    "            e.key_to_leaf_index,\n",
    "            e.local_expansions,\n",
    "            e.numpy_dtype,\n",
    "        )\n",
    "    l2p_vec[n] - time.time()-s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_times_mean['l2p_org'] = l2p_vec.mean()*1000\n",
    "wall_times_std['l2p_org'] = l2p_vec.std()*1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5a) P2M Wall Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrials = 5\n",
    "\n",
    "p2m_vec = np.zeros(ntrials)\n",
    "\n",
    "for n in range(ntrials):\n",
    "    e.backend['p2m'](\n",
    "            leaves=e.leaves,\n",
    "            nleaves=e.nleaves,\n",
    "            key_to_index=e.key_to_index,\n",
    "            key_to_leaf_index=e.key_to_leaf_index,\n",
    "            sources=e.sources,\n",
    "            source_densities=e.source_densities,\n",
    "            source_index_pointer=e.source_index_pointer,\n",
    "            multipole_expansions=e.multipole_expansions,\n",
    "            nequivalent_points=e.nequivalent_points,\n",
    "            x0=e.x0,\n",
    "            r0=e.r0,\n",
    "            alpha_outer=e.alpha_outer,\n",
    "            check_surface=e.check_surface,\n",
    "            ncheck_points=e.ncheck_points,\n",
    "            uc2e_inv_a=e.uc2e_inv_a,\n",
    "            uc2e_inv_b=e.uc2e_inv_b,\n",
    "            p2p_function=e.p2p_function,\n",
    "            scale_function=e.scale_function,\n",
    "            dtype=e.numpy_dtype\n",
    "        )\n",
    "    p2m_vec[n] - time.time()-s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_times_mean['p2m'] = p2m_vec.mean()*1000\n",
    "wall_times_std['p2m'] = p2m_vec.mean()*1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5b) P2M Data Organization Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401 ms ± 1.4 ms per loop (mean ± std. dev. of 5 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "ntrials = 5\n",
    "\n",
    "p2m_vec = np.zeros(ntrials)\n",
    "\n",
    "for n in range(ntrials):\n",
    "    s = time.time()\n",
    "    prepare_p2m_data(\n",
    "            e.leaves,\n",
    "            e.nleaves,\n",
    "            e.sources,\n",
    "            e.source_densities,\n",
    "            e.source_index_pointer,\n",
    "            e.key_to_leaf_index,\n",
    "            e.x0,\n",
    "            e.r0,\n",
    "            e.alpha_outer,\n",
    "            e.check_surface,\n",
    "            e.ncheck_points,\n",
    "            e.p2p_function,\n",
    "            e.scale_function,\n",
    "            e.numpy_dtype\n",
    "    )\n",
    "    p2m_vec[n] - time.time()-s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_times_mean['p2m_org'] = p2m_vec.mean()*1000\n",
    "wall_times_std['p2m_org'] = p2m_vec.std()*1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6, 7) M2M and L2L Wall Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrials = 5\n",
    "m2mvec = []\n",
    "\n",
    "for n in range(ntrials):\n",
    "    \n",
    "    s = time.time()\n",
    "    for level in range(e.depth, 0, -1):\n",
    "        keys = e.complete[e.complete_levels == level]\n",
    "        m2m(keys, e.multipole_expansions, e.m2m, e.key_to_index, e.nequivalent_points)\n",
    "    m2mvec.append(time.time()-s)\n",
    "    \n",
    "m2mvec = np.array(m2mvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_times_mean['m2m'] = m2mvec.mean()*1000\n",
    "wall_times_std['m2m'] = m2mvec.std()*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrials = 5\n",
    "l2lvec = []\n",
    "\n",
    "for n in range(ntrials):\n",
    "    \n",
    "    s = time.time()\n",
    "    for level in range(2, e.depth+1):\n",
    "        keys = e.complete[e.complete_levels == level]\n",
    "        l2l(keys, e.local_expansions, e.l2l, e.key_to_index, e.nequivalent_points)\n",
    "    l2lvec.append(time.time()-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2lvec = np.array(l2lvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_times_mean['l2l'] = l2lvec.mean()*1000\n",
    "wall_times_std['l2l'] = l2lvec.std()*1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M2M and L2L Data Organization Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 µs ± 57.6 µs per loop (mean ± std. dev. of 10 runs, 2 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 2\n",
    "for level in range(e.depth, 0, -1):\n",
    "    keys = e.complete[e.complete_levels == level]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 µs ± 58.4 µs per loop (mean ± std. dev. of 10 runs, 2 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 2\n",
    "for level in range(2, e.depth+1):\n",
    "    keys = e.complete[e.complete_levels == level]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6890000000000001"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "689e-6/1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8a) M2L Wall Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrials = 5\n",
    "\n",
    "m2lvec = np.zeros(ntrials)\n",
    "\n",
    "for n in range(ntrials):\n",
    "    start = time.time()\n",
    "    for level in range(2, e.depth+1):\n",
    "        # Keys at this level\n",
    "        keys = e.complete[e.complete_levels == level]\n",
    "        scale = e.numpy_dtype(e.scale_function(level))\n",
    "\n",
    "        # V List interactions\n",
    "        # M2L operator stored in terms of its SVD components for each level\n",
    "        str_level = str(level)\n",
    "        u = e.m2l[str_level][\"u\"][...]\n",
    "        s = np.diag(e.m2l[str_level][\"s\"][...])\n",
    "        vt = e.m2l[str_level][\"vt\"][...]\n",
    "\n",
    "        # Hashed transfer vectors for a given level, provide index for M2L operators\n",
    "        hashes = e.m2l[str_level][\"hashes\"][...]\n",
    "\n",
    "        hash_to_index = numba.typed.Dict.empty(\n",
    "            key_type=numba.types.int64,\n",
    "            value_type=numba.types.int64\n",
    "        )\n",
    "\n",
    "        for i, hash in enumerate(hashes):\n",
    "            hash_to_index[hash] = i\n",
    "\n",
    "        e.backend['m2l'](\n",
    "            keys=keys,\n",
    "            v_lists=e.v_lists,\n",
    "            u=u,\n",
    "            s=s,\n",
    "            vt=vt,\n",
    "            dc2e_inv_a=e.dc2e_inv_a,\n",
    "            dc2e_inv_b=e.dc2e_inv_b,\n",
    "            multipole_expansions=e.multipole_expansions,\n",
    "            local_expansions=e.local_expansions,\n",
    "            nequivalent_points=e.nequivalent_points,\n",
    "            key_to_index=e.key_to_index,\n",
    "            hash_to_index=hash_to_index,\n",
    "            scale=scale\n",
    "        )\n",
    "    m2lvec[n] = time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_times_mean['m2l'] = m2lvec.mean()\n",
    "wall_times_std['m2l'] = m2lvec.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.20830979347229"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wall_times_mean['m2l']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8b) M2L Data Organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.5 ms ± 106 µs per loop (mean ± std. dev. of 5 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "# %%timeit -n 5 -r 5\n",
    "# for level in range(2, e.depth+1):\n",
    "#     # Keys at this level\n",
    "#     keys = e.complete[e.complete_levels == level]\n",
    "#     scale = e.numpy_dtype(e.scale_function(level))\n",
    "\n",
    "#     # V List interactions\n",
    "#     # M2L operator stored in terms of its SVD components for each level\n",
    "#     str_level = str(level)\n",
    "#     u = e.m2l[str_level][\"u\"][...]\n",
    "#     s = np.diag(e.m2l[str_level][\"s\"][...])\n",
    "#     vt = e.m2l[str_level][\"vt\"][...]\n",
    "\n",
    "#     # Hashed transfer vectors for a given level, provide index for M2L operators\n",
    "#     hashes = e.m2l[str_level][\"hashes\"][...]\n",
    "\n",
    "#     hash_to_index = numba.typed.Dict.empty(\n",
    "#         key_type=numba.types.int64,\n",
    "#         value_type=numba.types.int64\n",
    "#     )\n",
    "\n",
    "#     for i, hash in enumerate(hashes):\n",
    "#         hash_to_index[hash] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wall_times_mean['m2l_org'] = 61.5\n",
    "# wall_times_std['m2l_org'] = 0.106"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU Times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M2M and L2L CPU Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_times_mean = {}\n",
    "cpu_times_std = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrials = 5\n",
    "\n",
    "m2m_vec = np.zeros(ntrials)\n",
    "l2l_vec = np.zeros(ntrials)\n",
    "\n",
    "for i in range(ntrials):\n",
    "    cpu_times = {}\n",
    "\n",
    "    for level in range(e.depth, 0, -1):\n",
    "        keys = e.complete[e.complete_levels == level]\n",
    "        m2m(keys, e.multipole_expansions, e.m2m, e.key_to_index, e.nequivalent_points)\n",
    "\n",
    "    for level in range(2, e.depth+1):\n",
    "        keys = e.complete[e.complete_levels == level]\n",
    "        l2l(keys, e.local_expansions, e.l2l, e.key_to_index, e.nequivalent_points)\n",
    "\n",
    "    m2m_vec[i] = sum(cpu_times['m2m'])\n",
    "    l2l_vec[i] = sum(cpu_times['l2l'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_times_mean['m2m'] = m2m_vec.mean()/1e-3\n",
    "cpu_times_std['m2m'] = m2m_vec.std()/1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_times_mean['l2l'] = l2l_vec.mean()/1e-3\n",
    "cpu_times_std['l2l'] = l2l_vec.std()/1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M2L CPU Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrials = 5\n",
    "\n",
    "m2l_vec = np.zeros(ntrials)\n",
    "\n",
    "for n in range(ntrials):\n",
    "    \n",
    "    cpu_times = {}\n",
    "    \n",
    "    for level in range(2, e.depth+1):\n",
    "\n",
    "        # Keys at this level\n",
    "        keys = e.complete[e.complete_levels == level]\n",
    "        scale = e.numpy_dtype(e.scale_function(level))\n",
    "\n",
    "        # V List interactions\n",
    "        # M2L operator stored in terms of its SVD components for each level\n",
    "        str_level = str(level)\n",
    "        u = e.m2l[str_level][\"u\"][...]\n",
    "        s = np.diag(e.m2l[str_level][\"s\"][...])\n",
    "        vt = e.m2l[str_level][\"vt\"][...]\n",
    "\n",
    "        # Hashed transfer vectors for a given level, provide index for M2L operators\n",
    "        hashes = e.m2l[str_level][\"hashes\"][...]\n",
    "\n",
    "        hash_to_index = numba.typed.Dict.empty(\n",
    "            key_type=numba.types.int64,\n",
    "            value_type=numba.types.int64\n",
    "        )\n",
    "\n",
    "        for i, hash in enumerate(hashes):\n",
    "            hash_to_index[hash] = i\n",
    "    \n",
    "        m2l(\n",
    "            keys, e.v_lists, u, s, vt, e.dc2e_inv_a, e.dc2e_inv_b,\n",
    "            e.multipole_expansions, e.local_expansions, e.nequivalent_points,\n",
    "            e.key_to_index, hash_to_index, scale\n",
    "        )\n",
    "\n",
    "    m2l_vec[n] = sum(cpu_times['m2l'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_times_mean['m2l'] = m2l_vec.mean()/1e-3\n",
    "cpu_times_std['m2l'] = m2l_vec.std()/1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P2M CPU Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preperation\n",
    "ntrials = 5\n",
    "\n",
    "cpu_times = {}\n",
    "\n",
    "for n in range(ntrials):\n",
    "    prepare_p2m_data(\n",
    "            e.leaves, e.nleaves, e.sources, e.source_densities, e.source_index_pointer, e.key_to_leaf_index, \n",
    "            e.x0, e.r0, e.alpha_outer, e.check_surface, e.ncheck_points, e.p2p_function, e.scale_function, e.numpy_dtype,\n",
    "        )\n",
    "    \n",
    "\n",
    "p2m_prep_vec = np.array(cpu_times['prepare_p2m_data'])\n",
    "\n",
    "\n",
    "# Running operator\n",
    "scales, potentials = prepare_p2m_data(\n",
    "            e.leaves, e.nleaves, e.sources, e.source_densities, e.source_index_pointer, e.key_to_leaf_index, \n",
    "            e.x0, e.r0, e.alpha_outer, e.check_surface, e.ncheck_points, e.p2p_function, e.scale_function, e.numpy_dtype,\n",
    "        )\n",
    "\n",
    "cpu_times = {}\n",
    "for n in range(ntrials):\n",
    "    p2m_core(\n",
    "        e.leaves, e.nleaves, e.key_to_index, e.nequivalent_points, e.ncheck_points,\n",
    "        e.uc2e_inv_a, e.uc2e_inv_b, scales, e.multipole_expansions, potentials\n",
    "    )\n",
    "p2m_operator_vec = np.array(cpu_times['p2m_core'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_times_mean['p2m_org'] = p2m_prep_vec.mean()/1e-3\n",
    "cpu_times_std['p2m_org'] = p2m_prep_vec.std()/1e-3\n",
    "\n",
    "cpu_times_mean['p2m_op'] = p2m_operator_vec.mean()/1e-3\n",
    "cpu_times_std['p2m_op'] = p2m_operator_vec.std()/1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2P CPU Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_times = {}\n",
    "ntrials = 5\n",
    "for n in range(ntrials):\n",
    "    prepare_l2t_data(\n",
    "            e.leaves,\n",
    "            e.nleaves,\n",
    "            e.targets,\n",
    "            e.target_index_pointer,\n",
    "            e.equivalent_surface,\n",
    "            e.nequivalent_points,\n",
    "            e.x0,\n",
    "            e.r0,\n",
    "            e.alpha_outer,\n",
    "            e.key_to_index,\n",
    "            e.key_to_leaf_index,\n",
    "            e.local_expansions,\n",
    "            e.numpy_dtype,\n",
    "        )\n",
    "\n",
    "l2t_org_vec = np.array(cpu_times['prepare_l2t_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_times_mean['l2p_org'] = l2t_org_vec.mean()/1e-3\n",
    "cpu_times_std['l2p_org'] = l2t_org_vec.std()/1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_times = {}\n",
    "ntrials = 5\n",
    "for n in range(ntrials):\n",
    "    l2t(\n",
    "        e.leaves,\n",
    "        e.nleaves,\n",
    "        e.key_to_index,\n",
    "        e.key_to_leaf_index,\n",
    "        e.targets,\n",
    "        e.target_potentials,\n",
    "        e.target_index_pointer,\n",
    "        e.local_expansions,\n",
    "        e.x0,\n",
    "        e.r0,\n",
    "        e.alpha_outer,\n",
    "        e.equivalent_surface,\n",
    "        e.nequivalent_points,\n",
    "        e.p2p_parallel_function,\n",
    "        e.numpy_dtype\n",
    "    )\n",
    "\n",
    "l2t_op_vec = np.array(cpu_times['prepare_l2t_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_times_mean['l2p_op'] = l2t_op_vec.mean()/1e-3\n",
    "cpu_times_std['l2p_op'] = l2t_op_vec.std()/1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'m2m': 23.630094528198242,\n",
       " 'l2l': 22.908592224121094,\n",
       " 'm2l': 13464.285278320312,\n",
       " 'p2m_org': 408.48636627197266,\n",
       " 'p2m_op': 9.994220733642578,\n",
       " 'l2p_org': 289.0143871307373,\n",
       " 'l2p_op': 293.61572265625}"
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_times_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M2P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_times = {}\n",
    "ntrials = 5\n",
    "for n in range(ntrials):\n",
    "    m2t(\n",
    "        e.leaves,\n",
    "        e.nleaves,\n",
    "        e.w_lists,\n",
    "        e.targets,\n",
    "        e.target_index_pointer,\n",
    "        e.key_to_index,\n",
    "        e.key_to_leaf_index,\n",
    "        e.target_potentials,\n",
    "        e.multipole_expansions,\n",
    "        e.x0,\n",
    "        e.r0,\n",
    "        e.alpha_inner,\n",
    "        e.equivalent_surface,\n",
    "        e.nequivalent_points,\n",
    "        e.p2p_function,\n",
    "        e.gradient_function\n",
    "    )\n",
    "\n",
    "m2p_op_vec = np.array(cpu_times['m2t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_times_mean['m2p'] = m2p_op_vec.mean()/1e-3\n",
    "cpu_times_std['m2p'] = m2p_op_vec.std()/1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_times = {}\n",
    "ntrials = 5\n",
    "for n in range(ntrials):\n",
    "    s2l(\n",
    "        e.leaves,\n",
    "        e.nleaves,\n",
    "        e.sources,\n",
    "        e.source_densities,\n",
    "        e.source_index_pointer,\n",
    "        e.key_to_index,\n",
    "        e.key_to_leaf_index,\n",
    "        e.x_lists,\n",
    "        e.local_expansions,\n",
    "        e.x0,\n",
    "        e.r0,\n",
    "        e.alpha_inner,\n",
    "        e.check_surface,\n",
    "        e.nequivalent_points,\n",
    "        e.dc2e_inv_a,\n",
    "        e.dc2e_inv_b,\n",
    "        e.scale_function,\n",
    "        e.p2p_function,  \n",
    "        e.numpy_dtype\n",
    "    )\n",
    "p2l_op_vec = np.array(cpu_times['s2l'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_times_mean['s2l'] = p2l_op_vec.mean()/1e-3\n",
    "cpu_times_std['s2l'] = p2l_op_vec.std()/1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### near field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_times = {}\n",
    "ntrials = 5\n",
    "for n in range(ntrials):\n",
    "    near_field(\n",
    "        e.leaves,\n",
    "        e.nleaves,\n",
    "        e.key_to_leaf_index,\n",
    "        e.key_to_index,\n",
    "        e.targets,\n",
    "        e.u_lists,\n",
    "        e.target_index_pointer,\n",
    "        e.sources,\n",
    "        e.source_densities,\n",
    "        e.source_index_pointer,\n",
    "        e.target_potentials,\n",
    "        e.p2p_function,\n",
    "        e.gradient_function,\n",
    "    )\n",
    "    \n",
    "    \n",
    "nf_op_vec = np.array(cpu_times['near_field'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_times_mean['near_field'] = nf_op_vec.mean()/1e-3\n",
    "cpu_times_std['near_field'] = nf_op_vec.std()/1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'m2m': 23.630094528198242,\n",
       " 'l2l': 22.908592224121094,\n",
       " 'm2l': 13464.285278320312,\n",
       " 'p2m_org': 408.48636627197266,\n",
       " 'p2m_op': 9.994220733642578,\n",
       " 'l2p_org': 289.0143871307373,\n",
       " 'l2p_op': 293.61572265625,\n",
       " 'm2p': 6.160736083984375,\n",
       " 's2l': 401.17316246032715,\n",
       " 'near_field': 419.65417861938477}"
      ]
     },
     "execution_count": 676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_times_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_times = {'mean': cpu_times_mean, 'std': cpu_times_std}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_times = {'mean': wall_times_mean, 'std': wall_times_std}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('cpu_times.pkl', 'wb') as f:\n",
    "#     pickle.dump(cpu_times, f)\n",
    "# with open('wall_times.pkl', 'wb') as f:\n",
    "#     pickle.dump(wall_times, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'m2m': 23.630094528198242,\n",
       " 'l2l': 22.908592224121094,\n",
       " 'm2l': 13464.285278320312,\n",
       " 'p2m_org': 408.48636627197266,\n",
       " 'p2m_op': 9.994220733642578,\n",
       " 'l2p_org': 289.0143871307373,\n",
       " 'l2p_op': 293.61572265625,\n",
       " 'm2p': 6.160736083984375,\n",
       " 's2l': 401.17316246032715,\n",
       " 'near_field': 419.65417861938477}"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_times['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'near_field': 395.6580638885498,\n",
       " 'p2l': 392.9495334625244,\n",
       " 'm2p': 5.955839157104492,\n",
       " 'l2p_op': 381,\n",
       " 'l2p_org': 0.0,\n",
       " 'p2m_op': 411,\n",
       " 'p2m_org': 0.0,\n",
       " 'm2m_op': 22.9,\n",
       " 'm2m_org': 0.132,\n",
       " 'l2l_op': 0.02335224151611328,\n",
       " 'l2l_org': 0.123,\n",
       " 'm2l_org': 61.5,\n",
       " 'l2p': 0.0,\n",
       " 'p2m': 0.0,\n",
       " 'm2m': 25.437450408935547,\n",
       " 'l2l': 23.35224151611328}"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wall_times['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'m2l'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-686-6ea12d2d8360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcpu_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'm2m'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mwall_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'm2m'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcpu_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'l2l'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mwall_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'l2l'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcpu_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'm2l'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mwall_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'm2l'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#     cpu_times['mean']['m2p']/wall_times['mean']['m2p'],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#     (cpu_times['mean']['l2p_op'])/wall_times['mean']['l2p_op'],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'm2l'"
     ]
    }
   ],
   "source": [
    "fractions = [\n",
    "    cpu_times['mean']['m2m']/wall_times['mean']['m2m'],\n",
    "    cpu_times['mean']['l2l']/wall_times['mean']['l2l'],\n",
    "    cpu_times['mean']['m2l']/wall_times['mean']['m2l'],\n",
    "#     cpu_times['mean']['m2p']/wall_times['mean']['m2p'],\n",
    "#     (cpu_times['mean']['l2p_op'])/wall_times['mean']['l2p_op'],\n",
    "#     (cpu_times['mean']['p2m_op']+cpu_times['mean']['p2m_org'])/wall_times['mean']['p2m_op'],\n",
    "#     cpu_times['mean']['s2l']/wall_times['mean']['p2l'],\n",
    "#     cpu_times['mean']['near_field']/wall_times['mean']['near_field'],\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07649521365317737"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_times['std']['m2p']/wall_times['mean']['m2p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.928949016049878, 0.9810018540752902]"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu['times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02283883, 0.02165842, 0.02171707, 0.02165794, 0.02159572,\n",
       "       0.02179742, 0.02175617])"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2m_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax, fig = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fmm] *",
   "language": "python",
   "name": "conda-env-fmm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
